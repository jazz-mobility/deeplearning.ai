{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graded Lab: Tool Use and Reflective Agents\n",
    "\n",
    "In this lab, you will explore how AI agents can enhance research workflows by leveraging external tools and engaging in critical self-reflection.\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "- Chain steps into a research pipeline (**search → reflection → formatting**).\n",
    "- Convert natural-language output into **styled HTML** suitable for sharing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mresearch_tools\u001b[39;00m\n\u001b[32m      9\u001b[39m load_dotenv()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m CLIENT = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/Personal/deeplearning.ai/agentic-ai/.venv/lib/python3.12/site-packages/openai/_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import research_tools\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CLIENT = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Tools\n",
    "\n",
    "You'll use two research tools exposed in the `research_tools` module:\n",
    "- **`arxiv_search_tool(query, max_results)`** – academic papers via arXiv API.\n",
    "- **`tavily_search_tool(query, max_results, include_images)`** – general web search via Tavily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"linear algebra\"\n",
    "\n",
    "arxiv_results = research_tools.arxiv_search_tool(topic, max_results=3)\n",
    "\n",
    "for i, paper in enumerate(arxiv_results, 1):\n",
    "    if \"error\" in paper:\n",
    "        print(f\"Error: {paper['error']}\")\n",
    "    else:\n",
    "        print(f\"Paper {i}\")\n",
    "        print(f\"  Title     : {paper['title']}\")\n",
    "        print(f\"  Authors   : {', '.join(paper['authors'])}\")\n",
    "        print(f\"  Published : {paper['published']}\")\n",
    "        print(f\"  URL       : {paper['url']}\\n\")\n",
    "\n",
    "print(\"\\nRaw Results:\\n\")\n",
    "print(json.dumps(arxiv_results, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = \"retrieval-augmented generation applications\"\n",
    "\n",
    "tavily_results = research_tools.tavily_search_tool(topic)\n",
    "for item in tavily_results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Mapping\n",
    "\n",
    "Dictionary that maps tool names (strings) to actual Python functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOL_MAPPING = {\n",
    "    \"tavily_search_tool\": research_tools.tavily_search_tool,\n",
    "    \"arxiv_search_tool\": research_tools.arxiv_search_tool,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Generate Research Report with Tools\n",
    "\n",
    "**Goal:** Implement `generate_research_report_with_tools(prompt)`.\n",
    "\n",
    "This function generates a detailed research report with the assistance of online tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_research_report_with_tools(prompt: str, model: str = \"gpt-4o\") -> str:\n    \"\"\"\n    Generates a research report using OpenAI's tool-calling with arXiv and Tavily tools.\n\n    Args:\n        prompt (str): The user prompt.\n        model (str): OpenAI model name.\n\n    Returns:\n        str: Final assistant research report text.\n    \"\"\"\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": (\n                \"You are a research assistant that can search the web and arXiv to write detailed, \"\n                \"accurate, and properly sourced research reports.\\n\\n\"\n                \"Use tools when appropriate (e.g., to find scientific papers or web content).\\n\"\n                \"Cite sources whenever relevant. Do NOT omit citations for brevity.\\n\"\n                \"When possible, include full URLs (arXiv links, web sources, etc.).\\n\"\n                \"Use an academic tone, organize output into clearly labeled sections, and include \"\n                \"inline citations or footnotes as needed.\\n\"\n                \"Do not include placeholder text such as '(citation needed)' or '(citations omitted)'.\"\n            )\n        },\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n\n    tools = [research_tools.arxiv_tool_def, research_tools.tavily_tool_def]\n    max_turns = 10\n    final_text = \"\"\n    \n    for _ in range(max_turns):\n\n        ### START CODE HERE ###\n\n        response = CLIENT.chat.completions.create(\n            model=model,\n            messages=messages,\n            tools=tools,\n            tool_choice=\"auto\",\n            temperature=1,\n        )\n\n        ### END CODE HERE ###\n\n        msg = response.choices[0].message\n        messages.append(msg)\n\n        if not msg.tool_calls:\n            final_text = msg.content\n            print(\"Final answer:\")\n            print(final_text)\n            break\n\n        for call in msg.tool_calls:\n            tool_name = call.function.name\n            args = json.loads(call.function.arguments)\n            print(f\"Tool: {tool_name}({args})\")\n\n            try:\n                tool_func = TOOL_MAPPING[tool_name]\n                result = tool_func(**args)\n            except Exception as e:\n                result = {\"error\": str(e)}\n\n            ### START CODE HERE ###\n\n            new_msg = {\n                \"role\": \"tool\",\n                \"tool_call_id\": call.id,\n                \"name\": tool_name,\n                \"content\": json.dumps(result)\n            }\n\n            ### END CODE HERE ###\n\n            messages.append(new_msg)\n\n    return final_text"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Reflection + Rewrite\n",
    "\n",
    "**Goal:** Implement `reflection_and_rewrite(report)`.\n",
    "\n",
    "This function takes a report, analyzes it, generates a structured reflection, and produces an improved version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def reflection_and_rewrite(report, model: str = \"gpt-4o-mini\", temperature: float = 0.3) -> dict:\n    \"\"\"\n    Generates a structured reflection AND a revised research report.\n    Accepts raw text OR the messages list returned by generate_research_report_with_tools.\n\n    Returns:\n        dict with keys:\n          - \"reflection\": structured reflection text\n          - \"revised_report\": improved version of the input report\n    \"\"\"\n    report = research_tools.parse_input(report)\n\n    ### START CODE HERE ###\n\n    user_prompt = f\"\"\"Analyze the following research report and provide a structured reflection and revised version.\n\nReport:\n{report}\n\nYour response must be ONLY valid JSON with exactly this structure:\n{{\"reflection\": \"Your analysis covering Strengths, Limitations, Suggestions, and Opportunities\", \"revised_report\": \"Your improved version of the report\"}}\"\"\"\n\n    response = CLIENT.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": \"You are an academic reviewer and editor.\"},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ],\n        temperature=temperature\n    )\n\n    ### END CODE HERE ###\n\n    llm_output = response.choices[0].message.content.strip()\n\n    try:\n        data = json.loads(llm_output)\n    except json.JSONDecodeError:\n        raise Exception(\"The output of the LLM was not valid JSON. Adjust your prompt.\")\n\n    return {\n        \"reflection\": str(data.get(\"reflection\", \"\")).strip(),\n        \"revised_report\": str(data.get(\"revised_report\", \"\")).strip(),\n    }"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Convert Report to HTML\n",
    "\n",
    "**Goal:** Implement `convert_report_to_html(report)`.\n",
    "\n",
    "This function transforms a plain text research report into a well-structured HTML document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def convert_report_to_html(report, model: str = \"gpt-4o\", temperature: float = 0.5) -> str:\n    \"\"\"\n    Converts a plaintext research report into a styled HTML page using OpenAI.\n    Accepts raw text OR the messages list from the tool-calling step.\n    \"\"\"\n    report = research_tools.parse_input(report)\n\n    system_prompt = \"You convert plaintext reports into full clean HTML documents.\"\n\n    ### START CODE HERE ###\n\n    user_prompt = f\"\"\"Convert this research report into a well-structured HTML document with proper headings, paragraphs, and clickable links. Return ONLY valid HTML.\n\nReport:\n{report}\"\"\"\n\n    response = CLIENT.chat.completions.create(\n        model=model,\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": user_prompt},\n        ],\n        temperature=temperature\n    )\n\n    ### END CODE HERE ###\n\n    html = response.choices[0].message.content.strip()\n\n    return html"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-End Pipeline\n",
    "\n",
    "Run this cell to execute the full workflow:\n",
    "\n",
    "1. Generate a research report (tools)\n",
    "2. Reflect on the report\n",
    "3. Convert the report to HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_research_report_with_tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m prompt_ = \u001b[33m\"\u001b[39m\u001b[33mRadio observations of recurrent novae\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m preliminary_report = \u001b[43mgenerate_research_report_with_tools\u001b[49m(prompt_)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Research Report (preliminary) ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(preliminary_report)\n",
      "\u001b[31mNameError\u001b[39m: name 'generate_research_report_with_tools' is not defined"
     ]
    }
   ],
   "source": [
    "prompt_ = \"Radio observations of recurrent novae\"\n",
    "preliminary_report = generate_research_report_with_tools(prompt_)\n",
    "print(\"=== Research Report (preliminary) ===\\n\")\n",
    "print(preliminary_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reflection_and_rewrite' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m reflection_text = \u001b[43mreflection_and_rewrite\u001b[49m(preliminary_report)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Reflection on Report ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(reflection_text[\u001b[33m'\u001b[39m\u001b[33mreflection\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'reflection_and_rewrite' is not defined"
     ]
    }
   ],
   "source": [
    "reflection_text = reflection_and_rewrite(preliminary_report)\n",
    "print(\"=== Reflection on Report ===\\n\")\n",
    "print(reflection_text['reflection'], \"\\n\")\n",
    "print(\"=== Revised Report ===\\n\")\n",
    "print(reflection_text['revised_report'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_report_to_html' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m html = \u001b[43mconvert_report_to_html\u001b[49m(reflection_text[\u001b[33m'\u001b[39m\u001b[33mrevised_report\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Generated HTML (preview) ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m((html \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)[:\u001b[32m600\u001b[39m], \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m... [truncated]\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'convert_report_to_html' is not defined"
     ]
    }
   ],
   "source": [
    "html = convert_report_to_html(reflection_text['revised_report'])\n",
    "\n",
    "print(\"=== Generated HTML (preview) ===\\n\")\n",
    "print((html or \"\")[:600], \"\\n... [truncated]\\n\")\n",
    "\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrap-Up\n",
    "\n",
    "You built a mini research agent that can:\n",
    "- Call tools (arXiv + Tavily)\n",
    "- Reflect on its own output\n",
    "- Publish a clean HTML report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}